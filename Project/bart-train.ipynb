{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvedia-smi","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:43:41.939019Z","iopub.execute_input":"2023-10-27T21:43:41.939297Z","iopub.status.idle":"2023-10-27T21:43:42.874139Z","shell.execute_reply.started":"2023-10-27T21:43:41.939271Z","shell.execute_reply":"2023-10-27T21:43:42.873039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transformers installation\n! pip install transformers datasets\n! pip install transformers datasets evaluate rouge_score\n\n# To install from source instead of the last release, comment the command above and uncomment the following one.\n# ! pip install git+https://github.com/huggingface/transformers.git","metadata":{"id":"nwmlULlzZlQl","papermill":{"duration":20.990711,"end_time":"2023-10-02T06:34:22.601597","exception":false,"start_time":"2023-10-02T06:34:01.610886","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-27T21:44:19.559240Z","iopub.execute_input":"2023-10-27T21:44:19.560202Z","iopub.status.idle":"2023-10-27T21:44:47.953667Z","shell.execute_reply.started":"2023-10-27T21:44:19.560162Z","shell.execute_reply":"2023-10-27T21:44:47.952584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import huggingface_hub","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:44:47.955955Z","iopub.execute_input":"2023-10-27T21:44:47.956357Z","iopub.status.idle":"2023-10-27T21:44:47.967022Z","shell.execute_reply.started":"2023-10-27T21:44:47.956317Z","shell.execute_reply":"2023-10-27T21:44:47.966134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"hf\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:44:47.968112Z","iopub.execute_input":"2023-10-27T21:44:47.968409Z","iopub.status.idle":"2023-10-27T21:44:48.163756Z","shell.execute_reply.started":"2023-10-27T21:44:47.968375Z","shell.execute_reply":"2023-10-27T21:44:48.162963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"huggingface_hub.login(token = secret_value_0 ,write_permission =True )","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:44:51.102663Z","iopub.execute_input":"2023-10-27T21:44:51.103431Z","iopub.status.idle":"2023-10-27T21:44:51.546187Z","shell.execute_reply.started":"2023-10-27T21:44:51.103400Z","shell.execute_reply":"2023-10-27T21:44:51.545229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:44:53.722176Z","iopub.execute_input":"2023-10-27T21:44:53.722574Z","iopub.status.idle":"2023-10-27T21:45:05.252783Z","shell.execute_reply.started":"2023-10-27T21:44:53.722543Z","shell.execute_reply":"2023-10-27T21:45:05.251786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:45:05.254609Z","iopub.execute_input":"2023-10-27T21:45:05.254907Z","iopub.status.idle":"2023-10-27T21:45:06.545227Z","shell.execute_reply.started":"2023-10-27T21:45:05.254880Z","shell.execute_reply":"2023-10-27T21:45:06.544421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value = user_secrets.get_secret(\"wandb-key\")\n\n\nwandb.login(key=secret_value)","metadata":{"papermill":{"duration":3.0851,"end_time":"2023-10-02T06:34:25.693238","exception":false,"start_time":"2023-10-02T06:34:22.608138","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-27T21:46:32.371052Z","iopub.execute_input":"2023-10-27T21:46:32.372089Z","iopub.status.idle":"2023-10-27T21:46:35.995469Z","shell.execute_reply.started":"2023-10-27T21:46:32.372057Z","shell.execute_reply":"2023-10-27T21:46:35.994571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom glob import glob","metadata":{"id":"CriB55rKZlQo","papermill":{"duration":0.625476,"end_time":"2023-10-02T06:34:26.325394","exception":false,"start_time":"2023-10-02T06:34:25.699918","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-27T21:46:37.656832Z","iopub.execute_input":"2023-10-27T21:46:37.657941Z","iopub.status.idle":"2023-10-27T21:46:37.662281Z","shell.execute_reply.started":"2023-10-27T21:46:37.657904Z","shell.execute_reply":"2023-10-27T21:46:37.661241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use your fine tuning file\nfilename = \"/kaggle/input/bert-cls-in-abs/IN-abs_CLS.xlsx\"\n\ndf = pd.read_excel(filename,index_col=0)\ndf = df.reset_index(drop=True)  # Reset the index without creating a new column\ndf.rename(columns = {'data':'text', 'summary':'summary'}, inplace = True)\nlen(df)","metadata":{"papermill":{"duration":40.883634,"end_time":"2023-10-02T06:35:07.215925","exception":false,"start_time":"2023-10-02T06:34:26.332291","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-27T21:46:41.978810Z","iopub.execute_input":"2023-10-27T21:46:41.979203Z","iopub.status.idle":"2023-10-27T21:46:45.250079Z","shell.execute_reply.started":"2023-10-27T21:46:41.979174Z","shell.execute_reply":"2023-10-27T21:46:45.249103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:46:46.492526Z","iopub.execute_input":"2023-10-27T21:46:46.493108Z","iopub.status.idle":"2023-10-27T21:46:46.499261Z","shell.execute_reply.started":"2023-10-27T21:46:46.493075Z","shell.execute_reply":"2023-10-27T21:46:46.498399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = Dataset.from_pandas(df[['text', 'summary']])","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:46:48.189576Z","iopub.execute_input":"2023-10-27T21:46:48.190531Z","iopub.status.idle":"2023-10-27T21:46:48.326550Z","shell.execute_reply.started":"2023-10-27T21:46:48.190493Z","shell.execute_reply":"2023-10-27T21:46:48.325550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"papermill":{"duration":0.015226,"end_time":"2023-10-02T06:35:07.238036","exception":false,"start_time":"2023-10-02T06:35:07.222810","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-27T21:46:50.146689Z","iopub.execute_input":"2023-10-27T21:46:50.147106Z","iopub.status.idle":"2023-10-27T21:46:50.153081Z","shell.execute_reply.started":"2023-10-27T21:46:50.147077Z","shell.execute_reply":"2023-10-27T21:46:50.152076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.0001)","metadata":{"papermill":{"duration":0.026004,"end_time":"2023-10-02T06:35:07.270452","exception":false,"start_time":"2023-10-02T06:35:07.244448","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-27T21:46:53.304822Z","iopub.execute_input":"2023-10-27T21:46:53.305320Z","iopub.status.idle":"2023-10-27T21:46:53.341000Z","shell.execute_reply.started":"2023-10-27T21:46:53.305279Z","shell.execute_reply":"2023-10-27T21:46:53.340217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:46:54.725673Z","iopub.execute_input":"2023-10-27T21:46:54.726560Z","iopub.status.idle":"2023-10-27T21:46:54.732409Z","shell.execute_reply.started":"2023-10-27T21:46:54.726525Z","shell.execute_reply":"2023-10-27T21:46:54.731445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset[\"train\"][0]","metadata":{"papermill":{"duration":0.034414,"end_time":"2023-10-02T06:35:07.311388","exception":false,"start_time":"2023-10-02T06:35:07.276974","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-05T18:34:19.693486Z","iopub.execute_input":"2023-10-05T18:34:19.694400Z","iopub.status.idle":"2023-10-05T18:34:19.701979Z","shell.execute_reply.started":"2023-10-05T18:34:19.694375Z","shell.execute_reply":"2023-10-05T18:34:19.700852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading Model and tokenizer\nfrom transformers import BartTokenizer, BartForConditionalGeneration, AdamW, BartConfig\n\ntokenizer = BartTokenizer.from_pretrained('facebook/bart-large', add_prefix_space=True)\n\nbart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")","metadata":{"id":"-bI5SYtmZlQq","papermill":{"duration":3.52032,"end_time":"2023-10-02T06:35:10.855533","exception":false,"start_time":"2023-10-02T06:35:07.335213","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-27T21:47:08.107742Z","iopub.execute_input":"2023-10-27T21:47:08.108617Z","iopub.status.idle":"2023-10-27T21:47:41.423381Z","shell.execute_reply.started":"2023-10-27T21:47:08.108582Z","shell.execute_reply":"2023-10-27T21:47:41.422510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prefix = \"summarize: \"\n\n\ndef preprocess_function(examples):\n    inputs = [prefix + doc for doc in examples[\"text\"]]\n    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n\n    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"id":"OT8EPhRaZlQq","papermill":{"duration":0.016579,"end_time":"2023-10-02T06:35:10.896485","exception":false,"start_time":"2023-10-02T06:35:10.879906","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-27T21:49:27.025982Z","iopub.execute_input":"2023-10-27T21:49:27.027234Z","iopub.status.idle":"2023-10-27T21:49:27.032769Z","shell.execute_reply.started":"2023-10-27T21:49:27.027199Z","shell.execute_reply":"2023-10-27T21:49:27.031815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To apply the preprocessing function over the entire dataset, use ðŸ¤— Datasets [map](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) method. You can speed up the `map` function by setting `batched=True` to process multiple elements of the dataset at once:","metadata":{"id":"orgkDuBRZlQq","papermill":{"duration":0.007742,"end_time":"2023-10-02T06:35:10.912137","exception":false,"start_time":"2023-10-02T06:35:10.904395","status":"completed"},"tags":[]}},{"cell_type":"code","source":"tokenized_dataset = dataset.map(preprocess_function, batched=True)","metadata":{"id":"V3nOEoGVZlQr","papermill":{"duration":126.557864,"end_time":"2023-10-02T06:37:17.478006","exception":false,"start_time":"2023-10-02T06:35:10.920142","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-27T21:49:30.925615Z","iopub.execute_input":"2023-10-27T21:49:30.925996Z","iopub.status.idle":"2023-10-27T21:51:38.687165Z","shell.execute_reply.started":"2023-10-27T21:49:30.925967Z","shell.execute_reply":"2023-10-27T21:51:38.686237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n# Assuming tokenized_dataset is your tokenized dataset\nwith open('tokenized_dataset.pkl', 'wb') as pkl_file:\n    pickle.dump(tokenized_dataset, pkl_file)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:51:55.940184Z","iopub.execute_input":"2023-10-27T21:51:55.941136Z","iopub.status.idle":"2023-10-27T21:51:56.070608Z","shell.execute_reply.started":"2023-10-27T21:51:55.941100Z","shell.execute_reply":"2023-10-27T21:51:56.069625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now create a batch of examples using [DataCollatorForSeq2Seq](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorForSeq2Seq). It's more efficient to *dynamically pad* the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length.","metadata":{"id":"wS0Vpkr8ZlQr","papermill":{"duration":0.015599,"end_time":"2023-10-02T06:37:17.509722","exception":false,"start_time":"2023-10-02T06:37:17.494123","status":"completed"},"tags":[]}},{"cell_type":"code","source":"checkpoint = \"facebook/bart-large\"","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:51:58.578721Z","iopub.execute_input":"2023-10-27T21:51:58.579082Z","iopub.status.idle":"2023-10-27T21:51:58.583428Z","shell.execute_reply.started":"2023-10-27T21:51:58.579053Z","shell.execute_reply":"2023-10-27T21:51:58.582395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:52:41.286742Z","iopub.execute_input":"2023-10-27T21:52:41.287109Z","iopub.status.idle":"2023-10-27T21:52:41.797145Z","shell.execute_reply.started":"2023-10-27T21:52:41.287083Z","shell.execute_reply":"2023-10-27T21:52:41.796179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=bart_model)","metadata":{"id":"17l-1G4BZlQr","papermill":{"duration":8.639013,"end_time":"2023-10-02T06:37:26.164058","exception":false,"start_time":"2023-10-02T06:37:17.525045","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-27T21:53:16.756751Z","iopub.execute_input":"2023-10-27T21:53:16.757110Z","iopub.status.idle":"2023-10-27T21:53:16.761842Z","shell.execute_reply.started":"2023-10-27T21:53:16.757083Z","shell.execute_reply":"2023-10-27T21:53:16.760900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate","metadata":{"id":"KW34cOECZlQr","papermill":{"duration":0.008276,"end_time":"2023-10-02T06:37:26.181139","exception":false,"start_time":"2023-10-02T06:37:26.172863","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Including a metric during training is often helpful for evaluating your model's performance. You can quickly load a evaluation method with the ðŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index) library. For this task, load the [ROUGE](https://huggingface.co/spaces/evaluate-metric/rouge) metric (see the ðŸ¤— Evaluate [quick tour](https://huggingface.co/docs/evaluate/a_quick_tour) to learn more about how to load and compute a metric):","metadata":{"id":"avh76AkSZlQr","papermill":{"duration":0.010445,"end_time":"2023-10-02T06:37:26.201444","exception":false,"start_time":"2023-10-02T06:37:26.190999","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import evaluate\n\nrouge = evaluate.load(\"rouge\")","metadata":{"id":"dGLFI0znZlQr","papermill":{"duration":3.779585,"end_time":"2023-10-02T06:37:30.038855","exception":false,"start_time":"2023-10-02T06:37:26.259270","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-27T21:53:29.683990Z","iopub.execute_input":"2023-10-27T21:53:29.684886Z","iopub.status.idle":"2023-10-27T21:53:33.382467Z","shell.execute_reply.started":"2023-10-27T21:53:29.684851Z","shell.execute_reply":"2023-10-27T21:53:33.381499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then create a function that passes your predictions and labels to [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) to calculate the ROUGE metric:","metadata":{"id":"F5ReEPWHZlQr","papermill":{"duration":0.008261,"end_time":"2023-10-02T06:37:30.056011","exception":false,"start_time":"2023-10-02T06:37:30.047750","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"id":"657ymyU6ZlQs","papermill":{"duration":0.017913,"end_time":"2023-10-02T06:37:30.082304","exception":false,"start_time":"2023-10-02T06:37:30.064391","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-27T21:53:38.183382Z","iopub.execute_input":"2023-10-27T21:53:38.183770Z","iopub.status.idle":"2023-10-27T21:53:38.190968Z","shell.execute_reply.started":"2023-10-27T21:53:38.183738Z","shell.execute_reply":"2023-10-27T21:53:38.190022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Your `compute_metrics` function is ready to go now, and you'll return to it when you setup your training.","metadata":{"id":"EXLqn4N6ZlQs","papermill":{"duration":0.008178,"end_time":"2023-10-02T06:37:30.098902","exception":false,"start_time":"2023-10-02T06:37:30.090724","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Train","metadata":{"id":"ns_Z9gJzZlQs","papermill":{"duration":0.008245,"end_time":"2023-10-02T06:37:30.115417","exception":false,"start_time":"2023-10-02T06:37:30.107172","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"At this point, only three steps remain:\n\n1. Define your training hyperparameters in [Seq2SeqTrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Seq2SeqTrainingArguments). The only required parameter is `output_dir` which specifies where to save your model. You'll push this model to the Hub by setting `push_to_hub=True` (you need to be signed in to Hugging Face to upload your model). At the end of each epoch, the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) will evaluate the ROUGE metric and save the training checkpoint.\n2. Pass the training arguments to [Seq2SeqTrainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Seq2SeqTrainer) along with the model, dataset, tokenizer, data collator, and `compute_metrics` function.\n3. Call [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) to finetune your model.","metadata":{"id":"rPJmbHT8ZlQs","papermill":{"duration":0.009104,"end_time":"2023-10-02T06:37:52.271153","exception":false,"start_time":"2023-10-02T06:37:52.262049","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n","metadata":{"papermill":{"duration":0.015932,"end_time":"2023-10-02T06:37:52.295662","exception":false,"start_time":"2023-10-02T06:37:52.279730","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-27T21:54:24.806545Z","iopub.execute_input":"2023-10-27T21:54:24.807460Z","iopub.status.idle":"2023-10-27T21:54:24.811668Z","shell.execute_reply.started":"2023-10-27T21:54:24.807425Z","shell.execute_reply":"2023-10-27T21:54:24.810779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T21:56:07.816818Z","iopub.execute_input":"2023-10-27T21:56:07.817537Z","iopub.status.idle":"2023-10-27T21:56:07.846841Z","shell.execute_reply.started":"2023-10-27T21:56:07.817504Z","shell.execute_reply":"2023-10-27T21:56:07.845920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"bart-cls-n\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=1e-5,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=8,\n    predict_with_generate=True,\n    fp16=True,\n    push_to_hub=False,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=bart_model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"id":"JYc7D_F5ZlQs","papermill":{"duration":8463.476496,"end_time":"2023-10-02T08:58:55.780761","exception":false,"start_time":"2023-10-02T06:37:52.304265","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-10-27T21:56:09.642072Z","iopub.execute_input":"2023-10-27T21:56:09.643132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once training is completed, share your model to the Hub with the [push_to_hub()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub) method so everyone can use your model:","metadata":{"id":"5N5dBK6CZlQs","papermill":{"duration":0.009396,"end_time":"2023-10-02T08:58:55.800962","exception":false,"start_time":"2023-10-02T08:58:55.791566","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\nimport os\n\n# Define the directory where you want to save the model\noutput_directory = \"model\"\n\n# Create the directory if it doesn't exist\nif not os.path.exists(output_directory):\n    os.makedirs(output_directory)\n\n# Save the model, tokenizer, and configuration to the specified directory\nbart_model.save_pretrained(output_directory)\ntokenizer.save_pretrained(output_directory)\n\n","metadata":{"execution":{"iopub.execute_input":"2023-10-02T08:58:55.821311Z","iopub.status.busy":"2023-10-02T08:58:55.821000Z","iopub.status.idle":"2023-10-02T08:58:58.137252Z","shell.execute_reply":"2023-10-02T08:58:58.136265Z"},"id":"BvjclM12ZlQs","papermill":{"duration":2.328719,"end_time":"2023-10-02T08:58:58.139070","exception":false,"start_time":"2023-10-02T08:58:55.810351","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<Tip>\n\nFor a more in-depth example of how to finetune a model for summarization, take a look at the corresponding\n[PyTorch notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization.ipynb)\nor [TensorFlow notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb).\n\n</Tip>","metadata":{"id":"4qVqJH-VZlQs","papermill":{"duration":0.022528,"end_time":"2023-10-02T08:58:58.182403","exception":false,"start_time":"2023-10-02T08:58:58.159875","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# text = dataset[\"test\"][\"text\"]","metadata":{"execution":{"iopub.execute_input":"2023-10-02T08:58:58.225227Z","iopub.status.busy":"2023-10-02T08:58:58.224738Z","iopub.status.idle":"2023-10-02T08:58:58.268625Z","shell.execute_reply":"2023-10-02T08:58:58.267690Z"},"id":"_Df7SqNhZlQt","papermill":{"duration":0.063293,"end_time":"2023-10-02T08:58:58.270855","exception":false,"start_time":"2023-10-02T08:58:58.207562","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The simplest way to try out your finetuned model for inference is to use it in a [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline). Instantiate a `pipeline` for summarization with your model, and pass your text to it:","metadata":{"id":"nE-QAlVsZlQw","papermill":{"duration":0.009408,"end_time":"2023-10-02T08:58:58.290254","exception":false,"start_time":"2023-10-02T08:58:58.280846","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# # Load the saved model and tokenizer for testing\n# model = AutoModelForSeq2SeqLM.from_pretrained(output_directory)\n# tokenizer = AutoTokenizer.from_pretrained(output_directory)\n\n# # Instantiate a pipeline for summarization with the saved model\n# summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n\n# # Generate the summary\n# generated_summary = summarizer(text)\n\n# # Print the generated summary\n# print(generated_summary)\n","metadata":{"execution":{"iopub.execute_input":"2023-10-02T08:58:58.311194Z","iopub.status.busy":"2023-10-02T08:58:58.310237Z","iopub.status.idle":"2023-10-02T08:58:58.314764Z","shell.execute_reply":"2023-10-02T08:58:58.313912Z"},"papermill":{"duration":0.016741,"end_time":"2023-10-02T08:58:58.316451","exception":false,"start_time":"2023-10-02T08:58:58.299710","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r bart.zip /kaggle/working","metadata":{"execution":{"iopub.execute_input":"2023-10-02T08:58:58.336683Z","iopub.status.busy":"2023-10-02T08:58:58.336105Z","iopub.status.idle":"2023-10-02T09:01:50.793420Z","shell.execute_reply":"2023-10-02T09:01:50.792271Z"},"papermill":{"duration":172.469891,"end_time":"2023-10-02T09:01:50.795650","exception":false,"start_time":"2023-10-02T08:58:58.325759","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'bart.zip')","metadata":{"execution":{"iopub.execute_input":"2023-10-02T09:01:50.819355Z","iopub.status.busy":"2023-10-02T09:01:50.819036Z","iopub.status.idle":"2023-10-02T09:01:50.825713Z","shell.execute_reply":"2023-10-02T09:01:50.824779Z"},"papermill":{"duration":0.020509,"end_time":"2023-10-02T09:01:50.827355","exception":false,"start_time":"2023-10-02T09:01:50.806846","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\n\n# Define the name for your model on Hugging Face Hub\nhub_model_name = \"astro21/bart-cls_n\"\n\n# Save the model and tokenizer to the Hugging Face Model Hub\nbart_model.push_to_hub(hub_model_name)\ntokenizer.push_to_hub(hub_model_name)\n\n# Once the above is done, you can also save the configuration for the model\nbart_model.config.push_to_hub(hub_model_name)\n\n# Commit your changes\nbart_model.push_to_hub(hub_model_name, commit_message=\"Initial commit\")\n\nprint(f\"Model and tokenizer are now available on the Hugging Face Model Hub with the name: {hub_model_name}\")\n","metadata":{"papermill":{"duration":0.018088,"end_time":"2023-10-02T09:01:50.856732","exception":false,"start_time":"2023-10-02T09:01:50.838644","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.010706,"end_time":"2023-10-02T09:01:50.878125","exception":false,"start_time":"2023-10-02T09:01:50.867419","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}